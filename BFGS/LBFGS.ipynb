{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import scipy.optimize as optimize\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def initialize_weights(self,W1=0,W2=0,b1=0,b2=0):\n",
    "        if type(W1)== np.ndarray : self.W1 = W1\n",
    "        else : self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        if type(W2)== np.ndarray : self.W2 = W2\n",
    "        else : self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        if type(b1)== np.ndarray : self.b1 = b1\n",
    "        else : self.b1= np.random.randn(1,self.hiddenLayerSize)\n",
    "        if type(b2)== np.ndarray : self.b2 = b2\n",
    "        else : self.b2= np.random.randn(1,self.outputLayerSize)\n",
    "            \n",
    "    def __init__(self, Lambda=0,W1=0,W2=0,b1=0,b2=0):    \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 12\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 25\n",
    "        \n",
    "        self.initialize_weights(W1,W2,b1,b2)\n",
    "\n",
    "        self.Lambda = Lambda \n",
    "        \n",
    "    def forwardPropagation(self, X):\n",
    "        self.z2 = np.dot(X, self.W1) + self.b1\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2) + self.b2\n",
    "        yHat = self.z3 \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def relu(self,z):\n",
    "        z[z<0] = 0\n",
    "        return z\n",
    "    \n",
    "    def reluPrime(self,z):\n",
    "        z[z<=0] = 0\n",
    "        z[z>0] = 1\n",
    "        return z\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forwardPropagation(X)\n",
    "        j = (0.5*sum((y-self.yHat)**2) + (self.Lambda/2)*(np.sum(self.W1**2)+np.sum(self.W2**2)))/X.shape[0]\n",
    "        return j\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forwardPropagation(X)\n",
    "        \n",
    "        #delta3 = np.multiply(-(y-self.yHat), self.reluPrime(self.z3))\n",
    "        delta3 = -(y-self.yHat)\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW2 = (np.dot(self.a2.T, delta3) +  self.Lambda*self.W2)/X.shape[0]\n",
    "        dJdb2 = np.sum(delta3, axis=0,keepdims=True)/len(delta3)\n",
    "        \n",
    "        #print(self.yHat.shape,dJdW2.shape,self.a2.T.shape)\n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW1 = (np.dot(X.T, delta2) + self.Lambda*self.W1)/X.shape[0]\n",
    "        dJdb1 = np.sum(delta2, axis=0,keepdims=True)/len(delta2)\n",
    "        #print(dJdb1.shape)\n",
    "        #print('\\ndjdw1',dJdW1,'\\ndjdw2',dJdW2,'\\ndel3',delta3,'\\ndel2',delta2)\n",
    "        return dJdW1, dJdW2,dJdb1,dJdb2\n",
    "    \n",
    "    #Helper functions for interacting with other methods/classes\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 Rolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel(),self.b1.ravel(),self.b2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single parameter vector:\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize*self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end],(self.inputLayerSize, self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end],(self.hiddenLayerSize, self.outputLayerSize))\n",
    "        b1_end = W2_end + self.hiddenLayerSize\n",
    "        self.b1 = np.reshape(params[W2_end:b1_end],(1,self.hiddenLayerSize))\n",
    "        b2_end = b1_end + self.outputLayerSize\n",
    "        self.b2 = np.reshape(params[b1_end:b2_end],(1,self.outputLayerSize))\n",
    "            \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2, dJdb1, dJdb2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel(),dJdb1.ravel(),dJdb2.ravel()))\n",
    "    \n",
    "class Trainer(object):\n",
    "    def __init__(self,N,restarts=1):\n",
    "        self.N=N\n",
    "        self.restarts=restarts\n",
    "        \n",
    "    def callbackF(self,params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X,self.y))\n",
    "        self.testJ.append(self.N.costFunction(self.testX,self.testY))\n",
    "        \n",
    "    def costFunctionWrapper(self,params,X,y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X,y)\n",
    "        return cost\n",
    "    \n",
    "    def train(self,trainX,trainy,testX,testY):\n",
    "        self.X,self.testX=trainX,testX\n",
    "        self.y,self.testY=trainy,testY\n",
    "        \n",
    "        options = {'maxiter':6000,'disp':True,'gtol':5e-6,'eps':1e-2}\n",
    "        min_loss=100\n",
    "        for i in range(self.restarts):\n",
    "            if i%5==0 : print('res ',i)\n",
    "            self.J=[]\n",
    "            self.testJ=[]\n",
    "            if i!=0 : self.N.initialize_weights()\n",
    "            params0=self.N.getParams()\n",
    "            res = optimize.minimize(self.costFunctionWrapper,params0,jac=None,method='L-BFGS-B',args=(trainX,trainy),options=options,callback=self.callbackF)\n",
    "            if res.fun<min_loss : min_loss,_res,self._J,self._testJ=res.fun,res,self.J,self.testJ\n",
    "            \n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Narayan Kundu\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataa\", \"rb\") as input_file:\n",
    "   df = pickle.load(input_file)\n",
    "df['CH2']=[np.nan]*len(df)\n",
    "for i in range(len(df)):\n",
    "    if df['CH2_SHELA'].iloc[i]!=-99 :\n",
    "        if df['CH2_SPIES'].iloc[i]!=-99 :\n",
    "            df['CH2'].iloc[i]=(df['CH2_SPIES'].iloc[i]+df['CH2_SHELA'].iloc[i])/2\n",
    "        else :\n",
    "            df['CH2'].iloc[i]=df['CH2_SHELA'].iloc[i]\n",
    "    elif df['CH2_SPIES'].iloc[i]!=-99 :\n",
    "        df['CH2'].iloc[i]=df['CH2_SPIES'].iloc[i]\n",
    "        df['CH1']=[np.nan]*len(df)\n",
    "for i in range(len(df)):\n",
    "    if df['CH1_SHELA'].iloc[i]!=-99 :\n",
    "        if df['CH1_SPIES'].iloc[i]!=-99 :\n",
    "            df['CH1'].iloc[i]=(df['CH1_SPIES'].iloc[i]+df['CH1_SHELA'].iloc[i])/2\n",
    "        else :\n",
    "            df['CH1'].iloc[i]=df['CH1_SHELA'].iloc[i]\n",
    "    elif df['CH1_SPIES'].iloc[i]!=-99 :\n",
    "        df['CH1'].iloc[i]=df['CH1_SPIES'].iloc[i]\n",
    "    else :\n",
    "        df['CH1'].iloc[i]=np.nan\n",
    "dff=df[['K','G','CH1','W1','U','Z','J','W2','I','H','R','CH2','REDSHIFT','REDSHIFT_ERR','ZWARNING']].dropna()\n",
    "dff[['K','G','CH1','W1','U','Z','J','W2','I','H','R','CH2','REDSHIFT']]=dff[['K','G','CH1','W1','U','Z','J','W2','I','H','R','CH2','REDSHIFT']].replace(-99,np.nan).dropna()\n",
    "dff=dff.where(dff['REDSHIFT_ERR']<dff['REDSHIFT']*0.1).dropna()\n",
    "dff=dff.sample(frac=1)\n",
    "X_data,y_data=dff[['K','G','CH1','W1','U','Z','J','W2','I','H','R','CH2']],dff['REDSHIFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inscaler = MinMaxScaler()\n",
    "Xs_data  = inscaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"start_time=time.time()\\nJtrain,Jtest,Res,dz_val,dz_train=modelrun(1e-5,10)\\nprint('evaluation time-',time.time()-start_time)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modelrun(Lambda=0,restarts=1):\n",
    "    N=int(len(Xs_data)/4)\n",
    "    Jtrain,Jtest,Res=[],[],[]\n",
    "    dz_val=[]\n",
    "    dz_train=[]\n",
    "    for i in range(4):\n",
    "        Xs_train,y_train=list(Xs_data.copy()),list(y_data.copy())\n",
    "        del Xs_train[i*N:i*N+N]\n",
    "        del y_train[i*N:i*N+N]\n",
    "        Xs_val,y_val=Xs_data[i*N:i*N+N],y_data[i*N:i*N+N]\n",
    "        \n",
    "        ouscaler= MinMaxScaler()\n",
    "        ys_train= ouscaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "        ys_val  = ouscaler.transform(np.array(y_val).reshape(-1,1))\n",
    "        \n",
    "        Xs_train,Xs_val,ys_train,ys_val,y_val,y_train=np.array(Xs_train),np.array(Xs_val),np.array(ys_train),np.array(ys_val),np.array(y_val),np.array(y_train)\n",
    "        X,y,testX,testY=Xs_train,ys_train,Xs_val,ys_val\n",
    "        \n",
    "        if i>0 : NN=NeuralNetwork(Lambda,W1,W2,b1,b2)\n",
    "        else : NN=NeuralNetwork(Lambda)\n",
    "        T=Trainer(NN,restarts)\n",
    "        T.train(X,y,testX,testY)\n",
    "        \n",
    "        Jtrain.append(T._J)\n",
    "        Jtest.append(T._testJ)\n",
    "        Res.append(T.optimizationResults)\n",
    "\n",
    "        pred_train=ouscaler.inverse_transform(NN.forwardPropagation(X)).reshape(len(y_train))\n",
    "        pred_val=ouscaler.inverse_transform(NN.forwardPropagation(testX)).reshape(len(y_val))\n",
    "        dz_val.append(np.array((pred_val-y_val)/(1+y_val)))\n",
    "        dz_train.append(np.array((pred_train-y_train)/(1+y_train)))\n",
    "        W1,W2,b1,b2=T.N.W1,T.N.W2,T.N.b1,T.N.b2\n",
    "    print('std train:',np.mean([np.std(dz_train[i]) for i in range(4)]),'\\nmean train:',np.mean(np.abs([np.mean(dz_train[i]) for i in range(4)])))\n",
    "    print('std val:',np.mean([np.std(dz_val[i]) for i in range(4)]),'\\nmean val:',np.mean(np.abs([np.mean(dz_val[i]) for i in range(4)])))\n",
    "\n",
    "    return Jtrain,Jtest,Res,dz_val,dz_train,T\n",
    "'''start_time=time.time()\n",
    "Jtrain,Jtest,Res,dz_val,dz_train=modelrun(1e-5,10)\n",
    "print('evaluation time-',time.time()-start_time)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std train: [0.2108125249698903, 0.20580485881961674, 0.20205544105120066, 0.20240772345798622] \n",
      "mean train: [0.050562191976873144, 0.04023260933867623, 0.03715483680982789, 0.028722106322051074]\n",
      "std val: [0.1842324277270755, 0.21141350530013647, 0.22496753822566964, 0.20475360795566552] \n",
      "mean val: [0.04559936327113747, 0.05569108394099263, 0.023823882170808348, 0.03316345394768969]\n"
     ]
    }
   ],
   "source": [
    "print('std train:',[np.std(dz_train[i]) for i in range(4)],'\\nmean train:',[np.mean(dz_train[i]) for i in range(4)])\n",
    "print('std val:',[np.std(dz_val[i]) for i in range(4)],'\\nmean val:',[np.mean(dz_val[i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res  0\n",
      "res  5\n",
      "res  10\n",
      "res  0\n",
      "res  5\n",
      "res  10\n",
      "res  0\n",
      "res  5\n",
      "res  10\n",
      "res  0\n",
      "res  5\n",
      "res  10\n",
      "std train: 0.23631502150753103 \n",
      "mean train: 0.036655952350092606\n",
      "std val: 0.23534554153964327 \n",
      "mean val: 0.039536084001967405\n",
      "evaluation time- 2575.0343453884125\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "Jtrain,Jtest,Res,dz_val,dz_train,T=modelrun(0,15)\n",
    "#info.append(np.array(modelrun(0,10)))\n",
    "print('evaluation time-',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DictResDzvalDztrainW1W2b1b2.pkl', 'wb') as f:\n",
    "   pickle.dump([{'maxiter':6000,'gtol':1e-5,'lambda':0,'res':20},Res,dz_val,dz_train,W1,W2,b1,b2], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res  0\n",
      "res  0\n",
      "res  0\n",
      "res  0\n",
      "std train: 0.14385138398537908 \n",
      "mean train: 0.017771841405767083\n",
      "std val: 0.15736940545469336 \n",
      "mean val: 0.018278671305552517\n",
      "evaluation time- 2098.8036212921143\n"
     ]
    }
   ],
   "source": [
    "def modelrun(Lambda=0,restarts=1,W1=0,W2=0,b1=0,b2=0):\n",
    "    N=int(len(Xs_data)/4)\n",
    "    Jtrain,Jtest,Res=[],[],[]\n",
    "    dz_val=[]\n",
    "    dz_train=[]\n",
    "    for i in range(4):\n",
    "        Xs_train,y_train=list(Xs_data.copy()),list(y_data.copy())\n",
    "        del Xs_train[i*N:i*N+N]\n",
    "        del y_train[i*N:i*N+N]\n",
    "        Xs_val,y_val=Xs_data[i*N:i*N+N],y_data[i*N:i*N+N]\n",
    "        \n",
    "        ouscaler= MinMaxScaler()\n",
    "        ys_train= ouscaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "        ys_val  = ouscaler.transform(np.array(y_val).reshape(-1,1))\n",
    "        \n",
    "        Xs_train,Xs_val,ys_train,ys_val,y_val,y_train=np.array(Xs_train),np.array(Xs_val),np.array(ys_train),np.array(ys_val),np.array(y_val),np.array(y_train)\n",
    "        X,y,testX,testY=Xs_train,ys_train,Xs_val,ys_val\n",
    "        \n",
    "        NN=NeuralNetwork(Lambda,W1,W2,b1,b2)\n",
    "        T=Trainer(NN,restarts)\n",
    "        T.train(X,y,testX,testY)\n",
    "        \n",
    "        Jtrain.append(T._J)\n",
    "        Jtest.append(T._testJ)\n",
    "        Res.append(T.optimizationResults)\n",
    "\n",
    "        pred_train=ouscaler.inverse_transform(NN.forwardPropagation(X)).reshape(len(y_train))\n",
    "        pred_val=ouscaler.inverse_transform(NN.forwardPropagation(testX)).reshape(len(y_val))\n",
    "        dz_val.append(np.array((pred_val-y_val)/(1+y_val)))\n",
    "        dz_train.append(np.array((pred_train-y_train)/(1+y_train)))\n",
    "        W1,W2,b1,b2=T.N.W1,T.N.W2,T.N.b1,T.N.b2\n",
    "    print('std train:',np.mean([np.std(dz_train[i]) for i in range(4)]),'\\nmean train:',np.mean([np.mean(dz_train[i]) for i in range(4)]))\n",
    "    print('std val:',np.mean([np.std(dz_val[i]) for i in range(4)]),'\\nmean val:',np.mean([np.mean(dz_val[i]) for i in range(4)]))\n",
    "\n",
    "    return Jtrain,Jtest,Res,dz_val,dz_train,W1,W2,b1,b2\n",
    "start_time=time.time()\n",
    "Jtrain,Jtest,Res,dz_val,dz_train,W1,W2,b1,b2=modelrun(0,1,W1,W2,b1,b2)\n",
    "#info.append(np.array(modelrun(0,10)))\n",
    "print('evaluation time-',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std train: [0.17258629245730223, 0.16570616599526178, 0.16501018670227346, 0.1612063182866698] \n",
      "mean train: [0.02873889 0.0225872  0.02416945 0.02199843]\n",
      "std val: [0.2430584856418385, 0.20711618431743253, 0.16601741316176905, 0.17271801060344266] \n",
      "mean val: [0.03797506 0.04313295 0.02408865 0.00068956]\n"
     ]
    }
   ],
   "source": [
    "print('std train:',[np.std(dz_train[i]) for i in range(4)],'\\nmean train:',np.abs([np.mean(dz_train[i]) for i in range(4)]))\n",
    "print('std val:',[np.std(dz_val[i]) for i in range(4)],'\\nmean val:',np.abs([np.mean(dz_val[i]) for i in range(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31368288370690167, 0.6494939815095458),\n",
       " (0.3016873068883493, 0.6578411327809536),\n",
       " (0.07685393076630762, -0.14287281458955192),\n",
       " (0.31089825650658026, 0.6467057261658093)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(np.std(dz_val[i]),np.mean(dz_val[i])) for i in range(4)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
